## Keynote
<a href="https://www.cs.cornell.edu/home/halpern/"><b>Joseph Halpern</b></a>, Cornell University, US  <br><br>
<b>Title:</b> A Causal Analysis of Harm <br>
<b>Abstract:</b> It has proved notoriously difficult to define harm.  Indeed, it has been
claimed that the notion of harm is a "Frankensteinian jumble" that
should be replaced by other well-behaved notions.    On the other hand,
harm has become increasingly important as concerns about the potential harms
that may be caused by AI systems grow.  Indeed, the European Union's
draft AI act mentions "harm" over 25 times and points out that, given its
crucial role, it must be defined carefully.<br>

I start by defining a qualitative notion of harm that
uses causal models and is based on a well-known definition of actual
causality.  The key features of the definition
are that it is based on contrastive causation
and uses a default utility to which the utility of actual outcomes
is compared.  I show that our definition is able to handle
the  problematic examples from the literature.
I extend the definition to a quantitative notion of harm, first in the case
of a single individual, and then for groups of individuals.
I show that the ``obvious'' way
of doing this (just taking the expected harm for an individual and
then summing the expected harm over all individuals) can lead to
counterintuitive or inappropriate answers, and discuss alternatives,
drawing on work from the decision-theory literature.<br>

This is joint work with <a href="https://sanderbeckers.github.io/website/about/">Sander Beckers</a> and <a href="https://www.hanachockler.com">Hana Chockler</a>.

## Invited Talks
<a href="https://www.bell-labs.com/about/researcher-profiles/armen-aghasaryan/#gref"><b>Armen Aghasaryan</b></a>, Nokia Bell Labs, France<br><br>
<b>Title, Abstract:</b> TBA <br><br>

<a href="https://www.hanachockler.com"><b>Hana Chockler</b></a>, King's College London, UK  <br><br>
<b>Title, Abstract:</b> TBA <br>
